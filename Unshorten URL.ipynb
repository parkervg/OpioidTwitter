{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the requests library, there are many functions that will help us. $request.head()$ and $request.get()$ seem the most useful. I will illustrate below with a bad tweet: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [301]>\n"
     ]
    }
   ],
   "source": [
    "# Using 'https://t.co/I5HajUrJ61'\n",
    "import requests as rq \n",
    "r = rq.head('https://t.co/I5HajUrJ61'); \n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using head, we find our response code. 301. From wikipedia: \n",
    "\n",
    "The HTTP response status code 301: Moved Permanently is used for permanent URL redirection, meaning current links or records using the URL that the response is received for should be updated.\n",
    "\n",
    "Using 301 we can computationaly identify when the link is shortened.  \n",
    "\n",
    "Futher more, to find the unshortened the url we have: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/i/web/status/1188083344724185088'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unshortenedurl = rq.get('https://t.co/I5HajUrJ61')\n",
    "print(unshortenedurl)\n",
    "unshortenedurl.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HTTP code 200 implies that the request was successful. That is the new unshortened url points to the correct location. \n",
    "Lastly using .url will print our new extended url.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Branden's idea: Create a something that will check for the 301 condition if 301 is true, replace. \n",
    "\n",
    "In order to accomplish this we need to return only the code with $response.status$_$code$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unshorten_url(url):\n",
    "    r = rq.head(url);\n",
    "    if r.status_code == 301: \n",
    "        r = rq.get(url); # Pull the full url\n",
    "    return r.url # returns the url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/i/web/status/1188083344724185088'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unshorten_url('https://t.co/I5HajUrJ61')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this works when the code is 301, but there are many codes that will indicate a \"shortened\" url. A few examples are 302 and 300. Further research indicates a scheme for the response codes. From wiki:\n",
    "\n",
    "1xx informational response – the request was received, continuing process\n",
    "\n",
    "2xx successful – the request was successfully received, understood and accepted\n",
    "\n",
    "3xx redirection – further action needs to be taken in order to complete the request\n",
    "\n",
    "4xx client error – the request contains bad syntax or cannot be fulfilled\n",
    "\n",
    "5xx server error – the server failed to fulfill an apparently valid request\n",
    "\n",
    "Thus any code that begins with a 3 is a shortened url. To account for all the codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://twitter.com/i/web/status/1188083344724185088'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re # regular expression library\n",
    "def unshorten_url(url):\n",
    "    url = url\n",
    "    pattern = re.compile(r\"https?://[\\.A-Za-z0-9/]*\\s*\"); # This is a regular expression \n",
    "    match = pattern.findall(url)\n",
    "    r = rq.head(match[0]);\n",
    "    if int(r.status_code/100) ==  3: # int() will change any float that leads in 3 to an integer.  \n",
    "        r = rq.get(match[0]); # Pull the full url\n",
    "    return r.url # returns the url \n",
    "\n",
    "# To illustrate:\n",
    "unshorten_url('https://t.co/I5HajUrJ61')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expression allow us to pull the url from any string. For more info on how they work, I used this youtube video\n",
    "\n",
    "https://www.youtube.com/watch?v=K8L6KVGG-7o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the defintion on Parker's code: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID: 17942\n",
      "\n",
      "https://www.medschat.com/Discuss/Fill-Oxycodone-Prescription-222724.htm?utm_source=twitter&utm_medium=social&utm_campaign=social_media\n",
      "\n",
      "User: medschat\n",
      "_____________________________________________________________________________________________\n",
      "\n",
      "ID: 18456\n",
      "\n",
      "https://www.medschat.com/Discuss/Fill-Oxycodone-Prescription-222724.htm?utm_source=twitter&utm_medium=social&utm_campaign=social_media\n",
      "\n",
      "User: medschat\n",
      "_____________________________________________________________________________________________\n",
      "\n",
      "ID: 6047\n",
      "\n",
      "https://twitter.com/i/web/status/1181944617341726724\n",
      "\n",
      "User: HealthyLifePha3\n",
      "_____________________________________________________________________________________________\n",
      "\n",
      "ID: 6048\n",
      "\n",
      "https://twitter.com/i/web/status/1181944314722766848\n",
      "\n",
      "User: HealthyLifePha3\n",
      "_____________________________________________________________________________________________\n",
      "\n",
      "ID: 80456\n",
      "\n",
      "https://twitter.com/account/suspended\n",
      "\n",
      "User: EAdderall\n",
      "_____________________________________________________________________________________________\n",
      "\n",
      "ID: 472376\n",
      "\n",
      "https://twitter.com/account/suspended\n",
      "\n",
      "User: Michael53023557\n",
      "_____________________________________________________________________________________________\n",
      "\n",
      "ID: 554992\n",
      "\n",
      "https://twitter.com/account/suspended\n",
      "\n",
      "User: Selfcar32360137\n",
      "_____________________________________________________________________________________________\n",
      "\n",
      "ID: 554993\n",
      "\n",
      "https://twitter.com/account/suspended\n",
      "\n",
      "User: ecstasyhome\n",
      "_____________________________________________________________________________________________\n",
      "\n",
      "ID: 554994\n",
      "\n",
      "https://twitter.com/account/suspended\n",
      "\n",
      "User: JustHighAndHap1\n",
      "_____________________________________________________________________________________________\n",
      "\n",
      "ID: 554995\n",
      "\n",
      "https://twitter.com/i/web/status/1188083344724185088\n",
      "\n",
      "User: DRuleof\n",
      "_____________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\JungleBook\\Desktop\\DS Club\\OpioidTwitter-master\\data\\opioid_tweets.csv\")\n",
    "\n",
    "\n",
    "\n",
    "with open(r\"C:\\Users\\JungleBook\\Desktop\\DS Club\\OpioidTwitter-master\\bad_tweets.txt\", \"r\") as f:\n",
    "    ids = [i.strip() for i in f.read().split(\",\")] \n",
    "\n",
    "for item in df[df[\"id\"].isin(ids)].iterrows():\n",
    "    print()\n",
    "    print(\"ID: {}\".format(item[1][\"id\"]))\n",
    "    print()\n",
    "    print(unshorten_url(item[1][\"content\"]) )\n",
    "# The isssue is that item[1][\"Content] contains the text of tweet the url\"\n",
    "    print()\n",
    "    print(\"User: {}\".format(item[1][\"user_name\"]))\n",
    "    print(\"_____________________________________________________________________________________________\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we have a way to unshorten any url, regardless of where the url is placed withing a string. \n",
    "\n",
    "Concerns: While this might not work, we might need to add if statements for the other http codes(ie. 4xx, 2xx, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
